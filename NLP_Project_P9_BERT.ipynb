{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Project_P9_BERT.ipynb","provenance":[],"collapsed_sections":["0pmfUhmmJHkX","NT8ncxKgJRNm","hiZAbljINilw"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gqDoJ42gQ7Gb"},"source":["# **Project-P9 for CS60075: Natural Language Processing**\n","## Automated query processing from passages \n","Using BERT Model"]},{"cell_type":"markdown","metadata":{"id":"PbC0MdIRWN7_"},"source":["# Team Members (Group-3): \n","Jaisaikrishnan\n","\n","Shivam Bhosale\n","\n","Mayank agrawal\n","\n","\n","Arundhuti Nuskar"]},{"cell_type":"markdown","metadata":{"id":"0pmfUhmmJHkX"},"source":["# **Importing libraries**"]},{"cell_type":"code","metadata":{"id":"Y8SCF8ZhjF6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637771953999,"user_tz":-330,"elapsed":379,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}},"outputId":"2edff1b2-88f5-4449-b539-ebe409a3fa11"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"7iFTNi3URavR","executionInfo":{"status":"ok","timestamp":1637771954590,"user_tz":-330,"elapsed":2,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}}},"source":["import torch\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"m6FLV0pBSDeO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637771958594,"user_tz":-330,"elapsed":4006,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}},"outputId":"8675c0da-b76d-480e-f070-f6d92aa60d0c"},"source":["!pip install transformers"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","metadata":{"id":"t3y9PnfjV_WD","executionInfo":{"status":"ok","timestamp":1637771958596,"user_tz":-330,"elapsed":27,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}}},"source":["from transformers import BertForQuestionAnswering\n","from transformers import BertTokenizer"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTJBJD1yYyRI","executionInfo":{"status":"ok","timestamp":1637771965861,"user_tz":-330,"elapsed":7285,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}}},"source":["model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZjtf-zrodIp","executionInfo":{"status":"ok","timestamp":1637771965862,"user_tz":-330,"elapsed":53,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}}},"source":["from gensim.summarization.bm25 import BM25"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"qmsnqTK73WXW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637771966535,"user_tz":-330,"elapsed":720,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}},"outputId":"183d75c8-b6d1-4363-c62b-84e3185f7054"},"source":["import re\n","import nltk\n","\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize,sent_tokenize\n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = stopwords.words('english')\n","\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wnl = WordNetLemmatizer()"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"markdown","metadata":{"id":"NT8ncxKgJRNm"},"source":["# **Bert Model**"]},{"cell_type":"code","metadata":{"id":"qxZzBnARTUu0","executionInfo":{"status":"ok","timestamp":1637771966535,"user_tz":-330,"elapsed":95,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}}},"source":["class Bert:\n","\n","    def __init__(self, corpus):\n","      self.corpus = corpus\n","      self.bm25 = None\n","      self.passage_list = None # List of all the paragraphs in the corpus\n","\n","      self.preprocess()\n","    \n","    @staticmethod\n","    def tokenize(text):\n","      text = text.lower()\n","      text = re.sub('[^a-z0-9_]', ' ', text)\n","      text = re.sub(r'\\s+', ' ', text)\n","\n","      return [wnl.lemmatize(word) for word in word_tokenize(text) if not word in stop_words]\n","\n","    def preprocess(self):\n","      self.corpus = re.sub('\\n\\n', '\\n', self.corpus)\n","\n","      passages = [p for p in self.corpus.split('\\n') if p]\n","      self.passage_list = passages\n","\n","      passage_token_list = []\n","\n","      # remove stopwords, lemmatize, ...\n","      for passage in self.passage_list:\n","        passage_tokens = Bert.tokenize(passage)\n","        passage_token_list.append(passage_tokens)\n","\n","      self.bm25 = BM25(passage_token_list)\n","\n","\n","    def extract_passage(self, question):\n","\n","      question_tokens = Bert.tokenize(question)\n","      # print(question_tokens)\n","\n","      average_idf = sum(map(lambda k: float(self.bm25.idf[k]), self.bm25.idf.keys())) / len(self.bm25.idf.keys())\n","\n","      scores = self.bm25.get_scores(question_tokens, average_idf)\n","\n","      pairs = [(s, i) for i, s in enumerate(scores)]\n","      pairs.sort(reverse=True)\n","\n","\n","      return pairs[0][1]\n","      # return [i for _, i in pairs[:topn]]\n","\n","\n","\n","\n","    def process_query(self, question_list):\n","            \n","      answer_list = []\n","      \n","      for question in (question_list):\n","          cur_passage_ind = self.extract_passage(question)\n","          # print(cur_passage_ind)\n","\n","          text = self.passage_list[cur_passage_ind]\n","\n","          #tokenize question and text as a pair\n","          input_ids = tokenizer.encode(question, text)\n","          \n","          #string version of tokenized ids\n","          tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","          \n","          #segment IDs\n","          #first occurence of [SEP] token\n","          sep_idx = input_ids.index(tokenizer.sep_token_id) # [SEP]\n","          #number of tokens in segment A (question)\n","          num_seg_a = sep_idx+1\n","          #number of tokens in segment B (text)\n","          num_seg_b = len(input_ids) - num_seg_a\n","          \n","          #list of 0s and 1s for segment embeddings\n","          segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","          # print(\"len: \", len(input_ids))\n","          \n","          #model output using input_ids and segment_ids\n","          output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n","          \n","          #reconstructing the answer\n","          answer_start = torch.argmax(output.start_logits)\n","          answer_end = torch.argmax(output.end_logits)\n","\n","          answer = \"\"\n","\n","          if answer_end >= answer_start:\n","              answer = tokens[answer_start]\n","              for i in range(answer_start+1, answer_end+1):\n","                  if tokens[i][0:2] == \"##\":\n","                      answer += tokens[i][2:]\n","                  else:\n","                      answer += \" \" + tokens[i]\n","\n","          else:\n","              answer = \"Unable to find the answer to your question.\"\n","\n","          if answer.startswith(\"[CLS]\"):\n","              answer = \"Unable to find the answer to your question.\"\n","          \n","          answer_list.append(answer)\n","          # print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))\n","\n","      return answer_list"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I0fpRJ-CJ-kY"},"source":["# **Question Answering**"]},{"cell_type":"code","metadata":{"id":"zYOk0NtBej4g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637772265373,"user_tz":-330,"elapsed":298932,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}},"outputId":"63588bf7-ffb9-41ea-9d59-4eb4ab6d767c"},"source":["content = open(\"//content/drive/MyDrive/Colab Notebooks/NLP/NLP PROJECT/corpus.txt\",\"r\").read()\n","\n","bert_model = Bert(content)\n","\n","i=0\n","while(True):\n","  i += 1\n","  question = input(\"Enter the question: \")\n","  if(question == \"end\"):\n","      print(\"Good Bye!\")\n","      break\n","\n","  print(f\"Q{i}: {question}\")\n","  \n","  answer = bert_model.process_query([question])\n","\n","  print(\"Ans: \", answer[0])\n","  print(\"------------------------------------------------------------\")\n","\n","   "],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the question: What is the name of the satellite that measured the amount of dust?\n","Q1: What is the name of the satellite that measured the amount of dust?\n","Ans:  calipso satellite\n","------------------------------------------------------------\n","Enter the question: What did the analysis from the sediment deposits indicate?\n","Q2: What did the analysis from the sediment deposits indicate?\n","Ans:  rainfall in the basin during the lgm was lower than for the present\n","------------------------------------------------------------\n","Enter the question: Where is the majority of the rainforest contained?\n","Q3: Where is the majority of the rainforest contained?\n","Ans:  brazil\n","------------------------------------------------------------\n","Enter the question: What is the name of the book written by Archeologist Betty Meggers?\n","Q4: What is the name of the book written by Archeologist Betty Meggers?\n","Ans:  amazonia : man and culture in a counterfeit paradise\n","------------------------------------------------------------\n","Enter the question: What is the average plant biosmass?\n","Q5: What is the average plant biosmass?\n","Ans:  356 ± 47 tonnes per hectare\n","------------------------------------------------------------\n","Enter the question: When dating rocks, what is the absolute isotopic date applied to?\n","Q6: When dating rocks, what is the absolute isotopic date applied to?\n","Ans:  fossil sequences in which there was datable material\n","------------------------------------------------------------\n","Enter the question: What are the three major types of rock?\n","Q7: What are the three major types of rock?\n","Ans:  igneous , sedimentary , and metamorphic\n","------------------------------------------------------------\n","Enter the question: What types of waves do seismologists use to image the interior of the Earth?\n","Q8: What types of waves do seismologists use to image the interior of the Earth?\n","Ans:  seismic waves\n","------------------------------------------------------------\n","Enter the question: What principle relates to the formation of faults and the age of the sequences through which they cut?\n","Q9: What principle relates to the formation of faults and the age of the sequences through which they cut?\n","Ans:  the principle of cross - cutting relationships\n","------------------------------------------------------------\n","Enter the question: Where do thrust faults form?\n","Q10: Where do thrust faults form?\n","Ans:  key bed\n","------------------------------------------------------------\n","Enter the question: end\n","Good Bye!\n"]}]},{"cell_type":"markdown","metadata":{"id":"hiZAbljINilw"},"source":["# **Accuracy**"]},{"cell_type":"code","metadata":{"id":"M_qgAaMyJ7Ho","executionInfo":{"status":"ok","timestamp":1637772265374,"user_tz":-330,"elapsed":15,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}}},"source":["def compute_f1(prediction, truth):\n","    pred_tokens = Bert.tokenize(prediction)\n","    truth_tokens = Bert.tokenize(truth)\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    \n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","    \n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","    \n","    return 2 * (prec * rec) / (prec + rec)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18W5DaWrMkVt","executionInfo":{"status":"ok","timestamp":1637772396820,"user_tz":-330,"elapsed":20913,"user":{"displayName":"Jaisai Krishnan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjoYe3W_FqWgU8kKFYqD4oW77Y5ajbGPv4Yxp_U=s64","userId":"09166768171680843474"}},"outputId":"b9a29350-43b0-4828-f436-53db532ad54a"},"source":["questions = [\"What is the name of the satellite that measured the amount of dust?\",\n","\"What did the analysis from the sediment deposits indicate?\",\n","\"Where is the majority of the rainforest contained?\",\n","\"What is the name of the book written by Archeologist Betty Meggers?\",\n","\"What is the average plant biosmass?\",\n","\"When dating rocks, what is the absolute isotopic date applied to?\",\n","\"What are the three major types of rock?\",\n","\"What types of waves do seismologists use to image the interior of the Earth?\",\n","\"What principle relates to the formation of faults and the age of the sequences through which they cut?\",\n","\"Where do thrust faults form?\"]\n","\n","ground_truth = [\"CALIPSO\",\n","\"rainfall in the basin during the LGM was lower than for the present\",\n","\"Brazil\",\n","\"Amazonia: Man and Culture in a Counterfeit Paradise\",\n","\"356 ± 47 tonnes per hectare\",\n","\"fossil sequences\",\n","\"igneous, sedimentary, and metamorphic\",\n","\"seismic waves\",\n","\"he principle of cross-cutting relationships\",\n","\"In the shallow crust\"]\n","\n","predictions = []\n","bert_model = Bert(content)\n","\n","for i,answer in enumerate(bert_model.process_query(questions)):\n","  predictions.append(answer)\n","\n","f1_score = 0\n","best_f1_score = 0\n","for i,prediction in enumerate(predictions):\n","  cur = compute_f1(prediction, ground_truth[i])\n","  best_f1_score = max(cur, best_f1_score)\n","  f1_score += cur\n","\n","avg_f1_score = f1_score/len(predictions)\n","\n","print(\"Average F1 score is: \", avg_f1_score)\n","print(\"Best F1 scores is: \", best_f1_score)"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Average F1 score is:  0.8333333333333333\n","Best F1 scores is:  1.0\n"]}]}]}